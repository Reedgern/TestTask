{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи дедупликации будем использовать библиотеку dedupe, в котором используется машинное обучение.\n",
    "\n",
    "Основной код для запуска алгоритма взят из документации: https://dedupeio.github.io/dedupe-examples/docs/mysql_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import logging\n",
    "import json\n",
    "from getpass import getpass\n",
    "\n",
    "import MySQLdb\n",
    "import MySQLdb.cursors\n",
    "\n",
    "import dedupe\n",
    "import dedupe.backport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_pairs(result_set):\n",
    "    for i, row in enumerate(result_set):\n",
    "        a_record_id, a_record, b_record_id, b_record = row\n",
    "        record_a = (a_record_id, json.loads(a_record))\n",
    "        record_b = (b_record_id, json.loads(b_record))\n",
    "\n",
    "        yield record_a, record_b\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "\n",
    "            \n",
    "def cluster_ids(clustered_dupes):\n",
    "\n",
    "    for cluster, scores in clustered_dupes:\n",
    "        cluster_id = cluster[0]\n",
    "        for id, score in zip(cluster, scores):\n",
    "            yield id, cluster_id, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вводим логин и пароль для подключения к MySQL и указываем путь к файлам, используемым dedupe (если файлов нет, dedupe запустит процесс обучения и создаст файлы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter MySQL username: root\n",
      "Enter MySQL password: ········\n"
     ]
    }
   ],
   "source": [
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': input('Enter MySQL username: '),\n",
    "    'password': getpass('Enter MySQL password: '),\n",
    "}\n",
    "\n",
    "log_level = logging.DEBUG\n",
    "logging.getLogger().setLevel(log_level)\n",
    "\n",
    "settings_file = 'mysql_example_settings'\n",
    "training_file = 'mysql_example_training.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключаемся к базе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_con = MySQLdb.connect(**db_config, database='task3',\n",
    "                           charset='utf8',\n",
    "                           cursorclass=MySQLdb.cursors.SSDictCursor)\n",
    "\n",
    "write_con = MySQLdb.connect(**db_config, database='task3',\n",
    "                            charset='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем новую базу данных task3, внутри нее создаем таблицу outlets, заполняем ее с помощью запроса outlets.sql.\n",
    "\n",
    "Далее создаем таблицу с предобработанными данными (строки переводятся в нижний регистр)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with write_con.cursor() as cur:\n",
    "    cur.execute(\"drop database if exists task3\")\n",
    "    cur.execute(\"create database task3\")\n",
    "    cur.execute(\"use task3\")\n",
    "\n",
    "    with open('outlets.sql', encoding='utf-8', mode='r') as query:\n",
    "        cur.execute(query.read())\n",
    "        \n",
    "    cur.execute(\"CREATE TABLE processed_outlets AS \" \n",
    "          \"(SELECT id, \" \n",
    "          \" LOWER(`Город дистрибьютора`) AS city, \" \n",
    "          \" LOWER(Торг_точка_грязная) AS name, \" \n",
    "          \" LOWER(Торг_точка_грязная_адрес) AS address\" \n",
    "          \" FROM outlets)\")\n",
    " \n",
    "    cur.execute(\"CREATE INDEX processed_idx ON processed_outlets (id)\")\n",
    "        \n",
    "write_con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем dedupe: \n",
    "* Выбираем поля, которые важны при определении дубликатов;\n",
    "* Если файлов для обучения нет, запускаем процесс обучения (может занять много времени) - алгоритм будет выдавать пары записей и спрашивать, являются ли они одной и той же сущностью (ответы на выбор: да/нет/не уверен/завершить);\n",
    "* Если файлы уже есть (в данном случае мы уже провели обучение), то алгоритм просто считывает информацию из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:Predicate set:\n",
      "INFO:dedupe.api:(LevenshteinCanopyPredicate: (1, name), TfidfTextCanopyPredicate: (0.6, name), SimplePredicate: (oneGramFingerprint, name))\n",
      "INFO:dedupe.api:(SimplePredicate: (firstIntegerPredicate, address), TfidfNGramCanopyPredicate: (0.2, name), SimplePredicate: (fingerprint, address))\n",
      "INFO:dedupe.api:(SimplePredicate: (sameSevenCharStartPredicate, name), SimplePredicate: (nearIntegersPredicate, name), SimplePredicate: (oneGramFingerprint, address))\n",
      "INFO:dedupe.api:(LevenshteinCanopyPredicate: (4, name), LevenshteinCanopyPredicate: (3, address), SimplePredicate: (sortedAcronym, name))\n",
      "INFO:dedupe.api:(TfidfNGramCanopyPredicate: (0.6, address), SimplePredicate: (doubleMetaphone, name), SimplePredicate: (firstIntegerPredicate, address))\n",
      "INFO:dedupe.api:(TfidfNGramCanopyPredicate: (0.6, name), SimplePredicate: (commonIntegerPredicate, name), SimplePredicate: (metaphoneToken, name))\n",
      "INFO:dedupe.api:(SimplePredicate: (commonThreeTokens, name), SimplePredicate: (wholeFieldPredicate, address), TfidfNGramCanopyPredicate: (0.2, name))\n",
      "INFO:dedupe.api:(TfidfNGramCanopyPredicate: (0.4, name), SimplePredicate: (doubleMetaphone, name), LevenshteinCanopyPredicate: (1, address))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from  mysql_example_settings\n"
     ]
    }
   ],
   "source": [
    "OUTLET_SELECT = \"SELECT id, city, name, address \" \\\n",
    "               \"from processed_outlets\"\n",
    "\n",
    "if os.path.exists(settings_file):\n",
    "    print('reading from ', settings_file)\n",
    "    with open(settings_file, 'rb') as sf:\n",
    "        deduper = dedupe.StaticDedupe(sf, num_cores=4)\n",
    "else:\n",
    "\n",
    "    fields = [{'field': 'name', 'type': 'String'},\n",
    "              {'field': 'address', 'type': 'String'},\n",
    "              {'field': 'city', 'type': 'String'},\n",
    "              ]\n",
    "\n",
    "    deduper = dedupe.Dedupe(fields, num_cores=None)\n",
    "\n",
    "    with read_con.cursor() as cur:\n",
    "        cur.execute(OUTLET_SELECT)\n",
    "        temp_d = {i: row for i, row in enumerate(cur)}\n",
    "    \n",
    "    print('PRINT')\n",
    "    \n",
    "    if os.path.exists(training_file):\n",
    "        print('reading labeled examples from ', training_file)\n",
    "        with open(training_file) as tf:\n",
    "            deduper.prepare_training(temp_d, training_file=tf)\n",
    "    else:\n",
    "        deduper.prepare_training(temp_d)\n",
    "\n",
    "    del temp_d\n",
    "    \n",
    "    print('starting active labeling...')\n",
    "\n",
    "    dedupe.convenience.console_label(deduper)\n",
    "\n",
    "    with open(training_file, 'w') as tf:\n",
    "        deduper.write_training(tf)\n",
    "\n",
    "    deduper.train(recall=0.90)\n",
    "\n",
    "    with open(settings_file, 'wb') as sf:\n",
    "        deduper.write_settings(sf)\n",
    "\n",
    "    deduper.cleanup_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocking...\n",
      "creating blocking_map database\n"
     ]
    }
   ],
   "source": [
    "print('blocking...')\n",
    "\n",
    "print('creating blocking_map database')\n",
    "with write_con.cursor() as cur:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS blocking_map\")\n",
    "    cur.execute(\"CREATE TABLE blocking_map \"\n",
    "                \"(block_key VARCHAR(200), id INTEGER) \"\n",
    "                \"CHARACTER SET utf8 COLLATE utf8_unicode_ci\")\n",
    "\n",
    "write_con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating inverted index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:dedupe.blocking:Canopy: LevenshteinCanopyPredicate: (1, name)\n",
      "DEBUG:dedupe.blocking:Canopy: LevenshteinCanopyPredicate: (4, name)\n",
      "INFO:dedupe.canopy_index:Removing stop word ип\n",
      "INFO:dedupe.canopy_index:Removing stop word а\n",
      "INFO:dedupe.canopy_index:Removing stop word н\n",
      "INFO:dedupe.canopy_index:Removing stop word в\n",
      "INFO:dedupe.canopy_index:Removing stop word ооо\n",
      "INFO:dedupe.canopy_index:Removing stop word г\n",
      "INFO:dedupe.canopy_index:Removing stop word и\n",
      "DEBUG:dedupe.blocking:Canopy: TfidfTextCanopyPredicate: (0.6, name)\n",
      "INFO:dedupe.canopy_index:Removing stop word  г\n",
      "INFO:dedupe.canopy_index:Removing stop word в \n",
      "INFO:dedupe.canopy_index:Removing stop word ип\n",
      "INFO:dedupe.canopy_index:Removing stop word ов\n",
      "INFO:dedupe.canopy_index:Removing stop word  м\n",
      "INFO:dedupe.canopy_index:Removing stop word ва\n",
      "INFO:dedupe.canopy_index:Removing stop word ма\n",
      "INFO:dedupe.canopy_index:Removing stop word  а\n",
      "INFO:dedupe.canopy_index:Removing stop word ас\n",
      "INFO:dedupe.canopy_index:Removing stop word н \n",
      "INFO:dedupe.canopy_index:Removing stop word  н\n",
      "INFO:dedupe.canopy_index:Removing stop word ен\n",
      "INFO:dedupe.canopy_index:Removing stop word ин\n",
      "INFO:dedupe.canopy_index:Removing stop word ле\n",
      "INFO:dedupe.canopy_index:Removing stop word ни\n",
      "INFO:dedupe.canopy_index:Removing stop word с \n",
      "INFO:dedupe.canopy_index:Removing stop word ул\n",
      "INFO:dedupe.canopy_index:Removing stop word но\n",
      "INFO:dedupe.canopy_index:Removing stop word а \n",
      "INFO:dedupe.canopy_index:Removing stop word то\n",
      "INFO:dedupe.canopy_index:Removing stop word ор\n",
      "INFO:dedupe.canopy_index:Removing stop word ти\n",
      "INFO:dedupe.canopy_index:Removing stop word ар\n",
      "INFO:dedupe.canopy_index:Removing stop word ка\n",
      "INFO:dedupe.canopy_index:Removing stop word ск\n",
      "INFO:dedupe.canopy_index:Removing stop word ер\n",
      "INFO:dedupe.canopy_index:Removing stop word о \n",
      "INFO:dedupe.canopy_index:Removing stop word  о\n",
      "INFO:dedupe.canopy_index:Removing stop word ан\n",
      "INFO:dedupe.canopy_index:Removing stop word ре\n",
      "INFO:dedupe.canopy_index:Removing stop word ки\n",
      "INFO:dedupe.canopy_index:Removing stop word г \n",
      "INFO:dedupe.canopy_index:Removing stop word ст\n",
      "INFO:dedupe.canopy_index:Removing stop word аг\n",
      "INFO:dedupe.canopy_index:Removing stop word ол\n",
      "INFO:dedupe.canopy_index:Removing stop word ко\n",
      "INFO:dedupe.canopy_index:Removing stop word до\n",
      "INFO:dedupe.canopy_index:Removing stop word ро\n",
      "INFO:dedupe.canopy_index:Removing stop word нк\n",
      "INFO:dedupe.canopy_index:Removing stop word он\n",
      "INFO:dedupe.canopy_index:Removing stop word ра\n",
      "INFO:dedupe.canopy_index:Removing stop word ос\n",
      "DEBUG:dedupe.blocking:Canopy: TfidfNGramCanopyPredicate: (0.2, name)\n",
      "DEBUG:dedupe.blocking:Canopy: TfidfNGramCanopyPredicate: (0.6, name)\n",
      "DEBUG:dedupe.blocking:Canopy: TfidfNGramCanopyPredicate: (0.2, name)\n",
      "DEBUG:dedupe.blocking:Canopy: TfidfNGramCanopyPredicate: (0.4, name)\n",
      "DEBUG:dedupe.blocking:Canopy: LevenshteinCanopyPredicate: (3, address)\n",
      "DEBUG:dedupe.blocking:Canopy: LevenshteinCanopyPredicate: (1, address)\n",
      "INFO:dedupe.canopy_index:Removing stop word  у\n",
      "INFO:dedupe.canopy_index:Removing stop word а \n",
      "INFO:dedupe.canopy_index:Removing stop word ий\n",
      "INFO:dedupe.canopy_index:Removing stop word ки\n",
      "INFO:dedupe.canopy_index:Removing stop word ул\n",
      "INFO:dedupe.canopy_index:Removing stop word н \n",
      "INFO:dedupe.canopy_index:Removing stop word  1\n",
      "INFO:dedupe.canopy_index:Removing stop word ен\n",
      "INFO:dedupe.canopy_index:Removing stop word но\n",
      "INFO:dedupe.canopy_index:Removing stop word  п\n",
      "INFO:dedupe.canopy_index:Removing stop word ал\n",
      "INFO:dedupe.canopy_index:Removing stop word ев\n",
      "INFO:dedupe.canopy_index:Removing stop word м \n",
      "INFO:dedupe.canopy_index:Removing stop word  г\n",
      "INFO:dedupe.canopy_index:Removing stop word ая\n",
      "INFO:dedupe.canopy_index:Removing stop word ка\n",
      "INFO:dedupe.canopy_index:Removing stop word ск\n",
      "INFO:dedupe.canopy_index:Removing stop word  д\n",
      "INFO:dedupe.canopy_index:Removing stop word до\n",
      "INFO:dedupe.canopy_index:Removing stop word на\n",
      "INFO:dedupe.canopy_index:Removing stop word ну\n",
      "INFO:dedupe.canopy_index:Removing stop word ос\n",
      "INFO:dedupe.canopy_index:Removing stop word ст\n",
      "INFO:dedupe.canopy_index:Removing stop word у \n",
      "INFO:dedupe.canopy_index:Removing stop word  о\n",
      "INFO:dedupe.canopy_index:Removing stop word бл\n",
      "INFO:dedupe.canopy_index:Removing stop word вс\n",
      "INFO:dedupe.canopy_index:Removing stop word к \n",
      "INFO:dedupe.canopy_index:Removing stop word об\n",
      "INFO:dedupe.canopy_index:Removing stop word ор\n",
      "INFO:dedupe.canopy_index:Removing stop word ас\n",
      "INFO:dedupe.canopy_index:Removing stop word  р\n",
      "INFO:dedupe.canopy_index:Removing stop word г \n",
      "INFO:dedupe.canopy_index:Removing stop word ан\n",
      "INFO:dedupe.canopy_index:Removing stop word ко\n",
      "INFO:dedupe.canopy_index:Removing stop word та\n",
      "INFO:dedupe.canopy_index:Removing stop word  с\n",
      "INFO:dedupe.canopy_index:Removing stop word ад\n",
      "INFO:dedupe.canopy_index:Removing stop word рн\n",
      "INFO:dedupe.canopy_index:Removing stop word ол\n",
      "INFO:dedupe.canopy_index:Removing stop word ль\n",
      "INFO:dedupe.canopy_index:Removing stop word  м\n",
      "INFO:dedupe.canopy_index:Removing stop word ра\n",
      "INFO:dedupe.canopy_index:Removing stop word ле\n",
      "INFO:dedupe.canopy_index:Removing stop word  №\n",
      "INFO:dedupe.canopy_index:Removing stop word  2\n",
      "INFO:dedupe.canopy_index:Removing stop word ер\n",
      "INFO:dedupe.canopy_index:Removing stop word нс\n",
      "INFO:dedupe.canopy_index:Removing stop word № \n",
      "INFO:dedupe.canopy_index:Removing stop word ом\n",
      "INFO:dedupe.canopy_index:Removing stop word 47\n",
      "INFO:dedupe.canopy_index:Removing stop word 46\n",
      "DEBUG:dedupe.blocking:Canopy: TfidfNGramCanopyPredicate: (0.6, address)\n"
     ]
    }
   ],
   "source": [
    "print('creating inverted index')\n",
    "\n",
    "for field in deduper.fingerprinter.index_fields:\n",
    "    with read_con.cursor() as cur:\n",
    "        cur.execute(\"SELECT DISTINCT {field} FROM processed_outlets \"\n",
    "                    \"WHERE {field} IS NOT NULL\".format(field=field))\n",
    "        field_data = (list(row.values())[0] for row in cur)\n",
    "        deduper.fingerprinter.index(field_data, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing blocking map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.blocking:10000, 36.3222082 seconds\n",
      "INFO:dedupe.blocking:20000, 87.5578712 seconds\n"
     ]
    }
   ],
   "source": [
    "print('writing blocking map')\n",
    "\n",
    "with read_con.cursor() as read_cur:\n",
    "    read_cur.execute(OUTLET_SELECT)\n",
    "    full_data = ((row['id'], row) for row in read_cur)\n",
    "    b_data = deduper.fingerprinter(full_data)\n",
    "\n",
    "    with write_con.cursor() as write_cur:\n",
    "\n",
    "        write_cur.executemany(\"INSERT INTO blocking_map VALUES (%s, %s)\",\n",
    "                              b_data)\n",
    "\n",
    "write_con.commit()\n",
    "\n",
    "deduper.fingerprinter.reset_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index\n"
     ]
    }
   ],
   "source": [
    "print('creating index')\n",
    "with write_con.cursor() as cur:\n",
    "    cur.execute(\"CREATE UNIQUE INDEX bm_idx ON blocking_map (block_key, id)\")\n",
    "\n",
    "write_con.commit()\n",
    "read_con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем, к какому кластеру принадлежит каждая запись, и сохраняем в таблицу entity_map.\n",
    "Задача почти решена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering...\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:dedupe.api:matching done, begin clustering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating entity_map database\n"
     ]
    }
   ],
   "source": [
    "with read_con.cursor(MySQLdb.cursors.SSCursor) as read_cur:\n",
    "\n",
    "    read_cur.execute(\"\"\"\n",
    "           select a.id,\n",
    "                  json_object('city', a.city,\n",
    "                              'name', a.name,\n",
    "                              'address', a.address),\n",
    "                  b.id,\n",
    "                  json_object('city', b.city,\n",
    "                              'name', b.name,\n",
    "                              'address', b.address)\n",
    "           from (select DISTINCT l.id as east, r.id as west\n",
    "                 from blocking_map as l\n",
    "                 INNER JOIN blocking_map as r\n",
    "                 using (block_key)\n",
    "                 where l.id < r.id) ids\n",
    "           INNER JOIN processed_outlets a on ids.east=a.id\n",
    "           INNER JOIN processed_outlets b on ids.west=b.id\n",
    "           \"\"\")\n",
    "\n",
    "    print('clustering...')\n",
    "    clustered_dupes = deduper.cluster(deduper.score(record_pairs(read_cur)),\n",
    "                                      threshold=0.3)\n",
    "    \n",
    "    with write_con.cursor() as write_cur:\n",
    "\n",
    "        write_cur.execute(\"DROP TABLE IF EXISTS entity_map\")\n",
    "\n",
    "        print('creating entity_map database')\n",
    "        write_cur.execute(\"CREATE TABLE entity_map \"\n",
    "                          \"(id INTEGER, canon_id INTEGER, \"\n",
    "                          \" cluster_score FLOAT, PRIMARY KEY(id))\")\n",
    "\n",
    "        write_cur.executemany('INSERT INTO entity_map VALUES (%s, %s, %s)',\n",
    "                              cluster_ids(clustered_dupes))\n",
    "        \n",
    "write_con.commit()\n",
    "\n",
    "with write_con.cursor() as cur:\n",
    "    cur.execute(\"CREATE INDEX head_index ON entity_map (canon_id)\")\n",
    "\n",
    "write_con.commit()\n",
    "read_con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием entity_map обновляем сначала outlets_clean, а затем и outlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with write_con.cursor() as cur:\n",
    "    cur.execute('''\n",
    "    insert into outlets_clean (Торг_точка_чистый_адрес, id)\n",
    "    select distinct t1.Торг_точка_грязная_адрес, t2.canon_id\n",
    "    from outlets as t1\n",
    "    right join entity_map as t2\n",
    "    on t1.id = t2.canon_id;\n",
    "\n",
    "    update outlets\n",
    "    inner join (select t1.id as id, t2.canon_id as canon_id\n",
    "    from outlets as t1\n",
    "    left join entity_map as t2\n",
    "    on t1.id = t2.id) as t\n",
    "    on outlets.id = t.id\n",
    "    set outlets.outlet_clean_id = t.canon_id;\n",
    "    ''')\n",
    "\n",
    "write_con.commit()\n",
    "\n",
    "read_con.close()\n",
    "write_con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
